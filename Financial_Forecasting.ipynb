{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26941ed",
   "metadata": {
    "id": "c26941ed"
   },
   "source": [
    "# Financial Forecasting with Python\n",
    "\n",
    "We'll start by exploring a basic forecasting model using synthetic data to understand the fundamentals of time series forecasting. This will set the foundation for more complex analyses that you'll encounter in real-world financial data.\n",
    "\n",
    "## The Original Code: A Starting Point\n",
    "We begin with a Python script that generates synthetic financial data. This data simulates a simple financial time series with a linear trend and some random noise, mimicking a basic scenario in financial forecasting. We'll use this data to:\n",
    "\n",
    "- Understand the structure of time series data.\n",
    "- Learn how to split data appropriately for time series forecasting.\n",
    "- Explore the application of linear regression in a time series context.\n",
    "- Visualize and evaluate the performance of our forecasting model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82750c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f82750c3",
    "outputId": "8c3d9130-73ef-45e6-8239-8dd267245241"
   },
   "outputs": [],
   "source": [
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf3dd5",
   "metadata": {
    "id": "64bf3dd5"
   },
   "source": [
    "# Example Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NeyR-Phva_HC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "NeyR-Phva_HC",
    "outputId": "ba2f6a5d-99a7-4a93-9b1f-d803ed20c063"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Generate synthetic financial data with a trend\n",
    "np.random.seed(42)\n",
    "n_points = 100\n",
    "time = np.arange(n_points)\n",
    "trend = 0.5 * time + np.random.normal(scale=5, size=n_points)\n",
    "financial_data = pd.DataFrame({'Time': time, 'Trend': trend})\n",
    "\n",
    "print(financial_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559c788",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0559c788",
    "outputId": "ec3a8fd9-6be0-4a6d-80aa-c106a543a33c"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(0.8 * n_points)\n",
    "train_data = financial_data.head(train_size).copy()\n",
    "test_data = financial_data.tail(n_points - train_size).copy()\n",
    "\n",
    "# Fit a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_data[['Time']], train_data['Trend'])\n",
    "\n",
    "# Predict the trend for the test set\n",
    "test_data['Trend_Predicted'] = model.predict(test_data[['Time']])\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(test_data['Trend'], test_data['Trend_Predicted'])\n",
    "mse = mean_squared_error(test_data['Trend'], test_data['Trend_Predicted'])\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "# Plot the actual and predicted trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_data['Time'], train_data['Trend'], label='Training Data', marker='o')\n",
    "plt.plot(test_data['Time'], test_data['Trend'], label='Actual Trend', marker='o')\n",
    "plt.plot(test_data['Time'], test_data['Trend_Predicted'], label='Predicted Trend', linestyle='--', marker='o')\n",
    "plt.title('Financial Time Series Trend Forecasting')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Auto-fit ARIMA model\n",
    "auto_model = auto_arima(train_data['Trend'], seasonal=False, suppress_warnings=True)\n",
    "fit_model = auto_model.fit(train_data['Trend'])\n",
    "\n",
    "# Forecast the trend for the test set\n",
    "forecast = fit_model.predict(n_periods=len(test_data))\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(test_data['Trend'], forecast)\n",
    "mse = mean_squared_error(test_data['Trend'], forecast)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "# Plot the actual and predicted trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_data['Time'], train_data['Trend'], label='Training Data', marker='o')\n",
    "plt.plot(test_data['Time'], test_data['Trend'], label='Actual Trend', marker='o')\n",
    "plt.plot(test_data['Time'], forecast, label='Predicted Trend', linestyle='--', marker='o')\n",
    "plt.title('Financial Time Series Trend Forecasting with ARIMA (Auto-fit)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f3c57f",
   "metadata": {
    "id": "70f3c57f"
   },
   "source": [
    "# Financial Forecasting in Python: Code Summary\n",
    "\n",
    "## Overview\n",
    "This code is a hands-on introduction to financial forecasting using Python. We generate synthetic financial data and apply two different forecasting models: Linear Regression and ARIMA. The goal is to predict future trends based on historical data.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "### 1. Data Generation and Preprocessing\n",
    "- We start by creating synthetic financial data. This approach is great for learning as it avoids the complexities of real-world data.\n",
    "- The dataset is divided into two parts: training data for building our models and testing data for evaluating them.\n",
    "\n",
    "### 2. Linear Regression Model\n",
    "- First, we use a simple linear regression model. It's a basic yet powerful tool for trend forecasting.\n",
    "- After fitting the model to the training data, we make predictions for the test data.\n",
    "- We calculate Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE) to assess the model's accuracy.\n",
    "\n",
    "### 3. ARIMA Model\n",
    "- Next, we explore the ARIMA model, a more advanced method for time series forecasting.\n",
    "- `auto_arima` helps us automatically find the best parameters for the ARIMA model.\n",
    "- Like with linear regression, we evaluate the ARIMA model's performance using MAE, MSE, and RMSE.\n",
    "\n",
    "### 4. Visualization\n",
    "- We plot the actual and predicted trends for both models. This visual representation helps us understand how well our models are performing.\n",
    "- By comparing these plots, you can visually assess the accuracy of each model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a8550",
   "metadata": {
    "id": "4e6a8550"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d51c1d4d",
   "metadata": {
    "id": "d51c1d4d"
   },
   "source": [
    "# Time Series Analysis: Predicting Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b7a20",
   "metadata": {
    "id": "5c8b7a20"
   },
   "outputs": [],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d5076",
   "metadata": {
    "id": "147d5076"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "stock_data = yf.download('AAPL', start='2022-01-01', end='2024-01-01')\n",
    "stock_data.columns = [col[0] for col in stock_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9050cd-5811-4769-a824-33f49764cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = len(stock_data)\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3b5c9-f7fe-4f56-a631-d4f5b68da3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test sets\n",
    "train_size = int(0.8 * n_points)\n",
    "train_data = stock_data.head(train_size).copy()\n",
    "test_data = stock_data.tail(n_points - train_size).copy()\n",
    "\n",
    "# If Date is an index, reset it to make it a column\n",
    "if 'Date' not in train_data.columns and train_data.index.name == 'Date':\n",
    "    train_data = train_data.reset_index()\n",
    "    test_data = test_data.reset_index()\n",
    "\n",
    "# Convert Date to numerical format for regression\n",
    "if isinstance(train_data['Date'].iloc[0], (pd.Timestamp, np.datetime64)):\n",
    "    train_data['Date_Numeric'] = train_data['Date'].astype(np.int64) // 10**9\n",
    "    test_data['Date_Numeric'] = test_data['Date'].astype(np.int64) // 10**9\n",
    "else:\n",
    "    train_data['Date_Numeric'] = train_data['Date']\n",
    "    test_data['Date_Numeric'] = test_data['Date']\n",
    "\n",
    "# Calculate rolling average using a 7-day window\n",
    "train_data['Rolling_Avg_7d'] = train_data['Close'].rolling(window=7, min_periods=1).mean()\n",
    "\n",
    "# Add the same calculation for test data\n",
    "test_data['Rolling_Avg_7d'] = test_data['Close'].rolling(window=7, min_periods=1).mean()\n",
    "\n",
    "# Prepare data for linear regression with multiple features\n",
    "X_train = train_data[['Date_Numeric', 'Rolling_Avg_7d']].values  # Multiple features\n",
    "y_train = train_data['Close']\n",
    "\n",
    "# Fit a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the trend for the test set\n",
    "X_test = test_data[['Date_Numeric', 'Rolling_Avg_7d']].values\n",
    "test_data['Trend_Predicted'] = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(test_data['Close'], test_data['Trend_Predicted'])\n",
    "mse = mean_squared_error(test_data['Close'], test_data['Trend_Predicted'])\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "# Plot the actual and predicted trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_data['Date'], train_data['Close'], label='Training Data', marker='o')\n",
    "plt.plot(test_data['Date'], test_data['Close'], label='Actual Trend', marker='o')\n",
    "plt.plot(test_data['Date'], test_data['Trend_Predicted'], label='Predicted Trend', linestyle='--', marker='o')\n",
    "plt.title('Financial Time Series Trend Forecasting with Rolling Average')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb0902-f160-46d3-bf39-0d910a926755",
   "metadata": {},
   "source": [
    "Using the rolling 7-day average as a feature improves the prediction versus using the closing prices only.  The predicted trend closely maps to the actual trend, with a MAE of only 2.83 and a RMSE of only 3.44."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bfec3d",
   "metadata": {
    "id": "f0bfec3d"
   },
   "source": [
    "# Exponential Smoothing Overview\n",
    "\n",
    "## What is Exponential Smoothing?\n",
    "\n",
    "Exponential Smoothing is a time series forecasting method for univariate data. This technique is used to produce a smoothed time series, where the raw data points are weighted in such a way that the most recent data points have more influence on the forecast than older data points. It's particularly useful for data with trends and seasonal patterns.\n",
    "\n",
    "## How is Exponential Smoothing Created?\n",
    "\n",
    "The basic idea behind exponential smoothing is to compute the forecasted value at time `t` by applying weighted averages of past observations where the weights decay exponentially as observations get older. The formula for Simple Exponential Smoothing is:\n",
    "\n",
    "$$ \\hat{y}_{t+1} = \\alpha y_t + (1 - \\alpha) \\hat{y}_t $$\n",
    "\n",
    "where:\n",
    "- $\\hat{y}_{t+1}$ is the forecast for the next period.\n",
    "- $y_t$ is the actual value at time `t`.\n",
    "- $\\hat{y}_t$ is the forecasted value at time `t`.\n",
    "- $\\alpha$ is the smoothing factor, ranging from 0 to 1.\n",
    "\n",
    "## Unique Aspects of Exponential Smoothing\n",
    "\n",
    "- **Adaptability**: It can adapt more quickly to changes in the level of the series.\n",
    "- **Weighting**: Recent observations are given more weight, making it more responsive to changes in the data.\n",
    "- **Simplicity**: It requires fewer parameters and is easier to understand and compute.\n",
    "\n",
    "## When to Use Exponential Smoothing\n",
    "\n",
    "It's most effective when your data:\n",
    "- Shows no clear trend or seasonal patterns (Simple Exponential Smoothing).\n",
    "- Shows a trend but no seasonality (Double Exponential Smoothing).\n",
    "- Shows both trend and seasonality (Triple Exponential Smoothing, also known as Holt-Winters method).\n",
    "\n",
    "## Example with Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d0da5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "c94d0da5",
    "outputId": "8c963956-b654-4703-ffdb-35b51cdbdc35"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Hypothetical monthly sales data for two years\n",
    "data = [120, 130, 145, 160, 150, 165, 180, 200, 210, 205, 225, 240,\n",
    "        125, 135, 150, 170, 160, 175, 190, 210, 220, 215, 230, 245]\n",
    "\n",
    "# Convert data to pandas Series with a datetime index\n",
    "index = pd.date_range(start='2019-01-01', periods=len(data), freq='ME')\n",
    "series = pd.Series(data, index=index)\n",
    "\n",
    "# Apply Exponential Smoothing with trend and seasonality\n",
    "model = ExponentialSmoothing(series, trend='add', seasonal='add', seasonal_periods=12).fit()\n",
    "\n",
    "# Forecast the next 3 periods\n",
    "forecast = model.forecast(3)\n",
    "\n",
    "# Plot the original data and the forecast\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(series, label='Original')\n",
    "plt.plot(forecast, label='Forecast', linestyle='--')\n",
    "plt.title('Exponential Smoothing Forecast')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea42c5",
   "metadata": {
    "id": "1eea42c5"
   },
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df85611b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "df85611b",
    "outputId": "d5396562-4b7a-4d5f-d247-94cfe3e0a728"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Data Acquisition\n",
    "stock_data = yf.download('AAPL', start='2022-01-01', end='2024-01-01')\n",
    "stock_data.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "# Ensure proper DatetimeIndex with frequency for time series analysis\n",
    "stock_data.index = pd.to_datetime(stock_data.index)\n",
    "stock_data = stock_data.asfreq('B', method='ffill')  # Business days frequency\n",
    "\n",
    "print('-------Raw Data-------')\n",
    "print(stock_data.head())\n",
    "\n",
    "# Calculate rolling averages\n",
    "stock_data['7_day_avg'] = stock_data['Close'].rolling(window=7, min_periods=1).mean()\n",
    "stock_data['30_day_avg'] = stock_data['Close'].rolling(window=30, min_periods=1).mean()\n",
    "\n",
    "print('-------Engineered Data-------')\n",
    "print(stock_data.describe())\n",
    "\n",
    "# Split the data into training and test sets\n",
    "split_date = pd.to_datetime('2023-10-01')\n",
    "train = stock_data.loc[stock_data.index < split_date].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "test = stock_data.loc[stock_data.index >= split_date].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "# Prepare the training data for Exponential Smoothing\n",
    "y_train = train['Close']\n",
    "\n",
    "# Try different model configurations for better results\n",
    "model = ExponentialSmoothing(\n",
    "    y_train,\n",
    "    trend='mul',  # Using multiplicative trend instead of additive\n",
    "    seasonal=None,  # Removing seasonality as daily stock data often doesn't have strong seasonal patterns\n",
    "    damped_trend=True  # Using damped_trend\n",
    ").fit(optimized=True)  # Let the model find optimal smoothing parameters\n",
    "\n",
    "# Predict for the test period\n",
    "forecast_horizon = len(test)\n",
    "predictions = model.forecast(forecast_horizon)\n",
    "\n",
    "# Add predictions to test dataframe using .loc to avoid SettingWithCopyWarning\n",
    "test.loc[:, 'Predicted_Close'] = predictions.values\n",
    "\n",
    "# Calculate error metrics\n",
    "rmse = math.sqrt(mean_squared_error(test['Close'], test['Predicted_Close']))\n",
    "mape = np.mean(np.abs((test['Close'] - test['Predicted_Close']) / test['Close'])) * 100\n",
    "\n",
    "print(f\"Root Mean Square Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error: {mape:.2f}%\")\n",
    "\n",
    "# Visualization of Train and Test Datasets with improved predictions\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train.index, train['Close'], label='Train Data', color='blue')\n",
    "plt.plot(test.index, test['Close'], label='Actual Test Data', color='green')\n",
    "plt.plot(test.index, test['Predicted_Close'], label=f'Predicted Close (MAPE: {mape:.2f}%)', \n",
    "         linestyle='--', color='red', marker='.')\n",
    "\n",
    "# Add the rolling averages to the plot for comparison\n",
    "plt.plot(stock_data.index, stock_data['7_day_avg'], label='7-day Moving Average', \n",
    "         linestyle=':', color='purple', alpha=0.7)\n",
    "plt.plot(stock_data.index, stock_data['30_day_avg'], label='30-day Moving Average', \n",
    "         linestyle=':', color='orange', alpha=0.7)\n",
    "\n",
    "plt.title('AAPL Stock Price Prediction using Exponential Smoothing')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add vertical line to show train/test split\n",
    "plt.axvline(x=split_date, color='black', linestyle='--', alpha=0.7)\n",
    "plt.text(split_date, plt.ylim()[0], 'Train/Test Split', rotation=90, verticalalignment='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06e1ef-14d8-4eb9-87c1-08b0cb8a7dd0",
   "metadata": {
    "id": "f0985758"
   },
   "source": [
    "The projection doesn't seem to work as well as the Linear Regression with smoothed features.  RMSE is much higher, and the prediction doesn't follow the test data as well.\n",
    "Looking up the Exponential Smoothing model, we find that it is not designed to predict daily fluctuations.  Stock prices often follow a random walk pattern that is difficult to predict with series models.  An ARIMA model might do better."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
