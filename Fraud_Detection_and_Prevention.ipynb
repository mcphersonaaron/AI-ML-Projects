{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "813d3678",
      "metadata": {
        "id": "813d3678"
      },
      "source": [
        "#  Fraud Detection Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6578b98d",
      "metadata": {
        "id": "6578b98d"
      },
      "source": [
        "In this notebook, we explore and model a dataset of card transactions with the aim of detecting fraudulent activities. The provided dataset includes various features such as distance from home, transaction details, and purchase patterns, which are essential in understanding the characteristics of fraudulent transactions. You will use Python and key machine learning libraries to analyze this dataset, build a classification model, and evaluate its performance.\n",
        "\n",
        "## Base Code Provided\n",
        "- The base code includes necessary Python imports and a decision tree model for initial analysis.\n",
        "- You will start with a dataset of card transactions, exploring its structure, summary statistics, and event rate.\n",
        "- The base code will guide you through data loading, preprocessing, model training, and evaluation.\n",
        "- A visual representation of the decision tree will be created to help understand the model's decision-making process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c0ea5a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1c0ea5a0",
        "outputId": "e91af864-8729-473a-b2c9-65943b50aa1b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/marhcouto/fraud-detection/master/data/card_transdata.csv?raw=true'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Print the top 5 rows\n",
        "print(\"\\n--- First 5 rows of data ---\")\n",
        "print(data.head(5))\n",
        "\n",
        "# Print summary stats\n",
        "print(\"\\n--- Summary Statistics ---\")\n",
        "print(data.describe())\n",
        "\n",
        "# Event rate\n",
        "print(\"\\n--- Event Rate ---\")\n",
        "event_rate = data['fraud'].mean() * 100\n",
        "print(f'Event Rate: {event_rate:.2f}%')\n",
        "\n",
        "# Define the atrributes (X) and the label (y)\n",
        "X = data.drop('fraud', axis=1)\n",
        "y = data['fraud']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize a decision tree classifier\n",
        "model = DecisionTreeClassifier(max_depth=3) #max_depth is maximum number of levels in the tree\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"\\n--- Model Performance Metrics ---\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n",
        "\n",
        "# Visualize the decision tree\n",
        "plt.figure(figsize=(25, 10))\n",
        "plot_tree(model,\n",
        "          filled=True,\n",
        "          feature_names=['distance_from_home', 'distance_from_last_transaction', 'ratio_to_median_purchase_price',\n",
        "                         'repeat_retailer', 'used_chip', 'used_pin_number', 'online_order'],\n",
        "          class_names=['Non-Fraud', 'Fraud'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "384a84b9",
      "metadata": {
        "id": "384a84b9"
      },
      "source": [
        "## Fraud Detection Model Workflow Summary\n",
        "\n",
        "1. **Import Libraries**\n",
        "   - `pandas` for data handling.\n",
        "   - `numpy` for numerical operations.\n",
        "   - `sklearn` for machine learning tools.\n",
        "   - `matplotlib` for data visualization.\n",
        "\n",
        "2. **Load Dataset**\n",
        "   - Data is loaded from a remote URL using `pandas.read_csv`.\n",
        "\n",
        "3. **Initial Data Exploration**\n",
        "   - Initial examination using `data.head()` and `data.tail()` to understand dataset structure.\n",
        "\n",
        "4. **Data Preparation**\n",
        "   - Features (`X`) and target variable (`y`) are defined.\n",
        "   - `fraud` column is the target, while others are features.\n",
        "\n",
        "5. **Data Splitting**\n",
        "   - Dataset is split into training and test sets.\n",
        "   - `train_test_split` is used, with a test size of 20%.\n",
        "\n",
        "6. **Model Initialization**\n",
        "   - Decision Tree Classifier initialized with a maximum depth of 3.\n",
        "   - Limits complexity and overfitting of the model.\n",
        "\n",
        "7. **Model Training**\n",
        "   - Model is trained using the training set (`X_train`, `y_train`).\n",
        "\n",
        "8. **Prediction and Evaluation**\n",
        "   - Model predictions made on the test set.\n",
        "   - Evaluation using accuracy, confusion matrix, and classification report.\n",
        "\n",
        "9. **Visualization**\n",
        "   - Decision tree visualized using `matplotlib` and `sklearn.tree.plot_tree`.\n",
        "   - Helps in understanding the decision-making process of the model.\n",
        "\n",
        "# Commentary\n",
        "- This code effectively demonstrates the end-to-end process of a machine learning project.\n",
        "- Decision trees are a good choice for fraud detection due to their interpretability.\n",
        "- The model is simple yet provides a decent understanding of the basic approach to fraud detection in financial transactions.\n",
        "- Visualization is a key aspect, especially in complex domains like fraud detection, for understanding the model's decision criteria."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4949558",
      "metadata": {
        "id": "c4949558"
      },
      "source": [
        "# Model Performance Analysis and Commentary\n",
        "\n",
        "- **Data Overview**\n",
        "  - First 5 rows show a mix of numerical features like `distance_from_home`, `distance_from_last_transaction`, etc., crucial for predicting fraud.\n",
        "  - Summary statistics indicate a varied distribution of values, with some features having a wide range (e.g., `distance_from_home`).\n",
        "\n",
        "- **Model Accuracy**\n",
        "  - High accuracy of 98% suggests the model is very effective in classifying transactions as fraudulent or non-fraudulent.\n",
        "\n",
        "- **Confusion Matrix Analysis**\n",
        "  - Low number of false positives (2481) and false negatives (1646) compared to true positives and negatives.\n",
        "  - Indicates a good balance in identifying both fraudulent and non-fraudulent transactions accurately.\n",
        "\n",
        "- **Classification Report Insights**\n",
        "  - High precision (0.99) for class 0 (Non-Fraud) and good precision (0.86) for class 1 (Fraud).\n",
        "  - Recall is also high for both classes, especially for class 1 (0.91), which is critical in fraud detection.\n",
        "  - F1-scores are robust, indicating a balanced model considering both precision and recall.\n",
        "\n",
        "- **Overall Evaluation**\n",
        "  - The decision tree model shows excellent performance in identifying fraud.\n",
        "  - The balance between precision and recall, especially for fraud detection (class 1), is commendable.\n",
        "  - High accuracy combined with the detailed metrics suggest a well-tuned model for this dataset.\n",
        "  - The model could be further improved by exploring feature engineering, trying other algorithms, or tuning hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b780f80",
      "metadata": {
        "id": "6b780f80"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "deed417b",
      "metadata": {
        "id": "deed417b"
      },
      "source": [
        "# Comparative Analysis of Fraud Detection Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f4cbad6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2f4cbad6",
        "outputId": "0e72ec15-4ed0-4b3b-8223-57260e9b4793"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier                     #Import the Random Forest Classifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score     #Import additional metrics needed for the comparison\n",
        "\n",
        "#Calculate additional metrics for the Decision Tree (Model 1)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"\\n--- Decision Tree Model Performance Metrics ---\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n",
        "\n",
        "# Initialize a random forest classifier (Model 2).  Testing with an unpruned tree resulted in unrealistic\n",
        "# accuracy, precision, recall and f1 scores (all were 1.0)\n",
        "model2 = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=4,             # prune trees after 4 levels\n",
        "    min_samples_split=5,     # require at least 5 samples to split a node\n",
        "    min_samples_leaf=2,      # force leaves to have ≥2 samples\n",
        "    random_state=42     # for reproducibility\n",
        ")\n",
        "\n",
        "# Train the model on the training data\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred2 = model2.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy2 = accuracy_score(y_test, y_pred2)\n",
        "precision2 = precision_score(y_test, y_pred2)\n",
        "recall2 = recall_score(y_test, y_pred2)\n",
        "f12 = f1_score(y_test, y_pred2)\n",
        "confusion2 = confusion_matrix(y_test, y_pred2)\n",
        "classification_rep2 = classification_report(y_test, y_pred2)\n",
        "\n",
        "# Print the results\n",
        "print(\"\\n--- Random Forest Model Performance Metrics ---\")\n",
        "print(f\"Accuracy: {accuracy2:.2f}\")\n",
        "print(f\"Precision: {precision2:.2f}\")\n",
        "print(f\"Recall: {recall2:.2f}\")\n",
        "print(f\"F1-Score: {f12:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion2)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep2)\n",
        "\n",
        "# Visualize and compare the results using a bar chart\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
        "model1_scores = [accuracy, precision, recall, f1]   # e.g. [accuracy1, precision1, recall1]\n",
        "model2_scores = [accuracy2, precision2, recall2, f12]   # e.g. [accuracy2, precision2, recall2]\n",
        "\n",
        "# X-axis locations and bar width\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "# Create the grouped bar chart\n",
        "plt.figure()\n",
        "plt.bar(x - width/2, model1_scores, width, label='Decision Tree')\n",
        "plt.bar(x + width/2, model2_scores, width, label='Random Forest')\n",
        "\n",
        "# Labels and title\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel('Score')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.legend()\n",
        "\n",
        "# Display\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c3jy1VRNfae",
      "metadata": {
        "id": "2c3jy1VRNfae"
      },
      "source": [
        "1. **Model Evaluation**:\n",
        "   - The random forest model achieved an accuracy of 0.99, a precision of 1.00, a recall of 0.91, and an f1 score of 0.95.  \n",
        "   - Accuracy represents the percentage of correctly classified members among all members.  In this case, that is 198,374 out of 200,000, or 0.99.\n",
        "   - Precision represents the percentage of correctly classified positive members among all those classified as positive (in this case, fraudulent). Since there were 182,549 properly classified positive records out of 182,557, this rounds to 1.00.\n",
        "   - Recall represents the percentage of correctly classified negative members among all those classified as negative (in this case, non-fraud).  Since there were 15,825 members correctly classified as negative out of 17,443, this calculates to 0.91.\n",
        "   - The F1 score is (2 X precision X recall)/(precision + recall), or 0.95. It is a summary statistic that combines precision and recall, giving them equal weights.\n",
        "   - The confusion matrix shown above is used to calculate the previous metrics. It compares actual versus predicted classifications for all members of the dataset.\n",
        "2. **Comparative Analysis**:\n",
        "   - All of the scores for the Random Forest model were equal to or better than the scores for the Decision Tree model, as shown in the bar chart.\n",
        "3. **Reflection and Discussion**:\n",
        "   - The random forest model performed better than the decision tree model, although the first run with unpruned trees achieved scores of 1.00 across all scores, indicating overfitting.  This remains a risk with the pruned random forest; increasing the tree depth could probably achieve higher scores at the cost of overfitting.  One way to measure this risk would be to use cross-validation to evaluate the model over multiple test sets.\n",
        "   - The results are as one would expect, since the random forest is simply an ensemble of decision trees, taking the best results among the generated trees.  Ensemble models are usually better predictors than single models, because they combine the results of multiple models, reducing the risk of random results being suboptimal.\n",
        "   - With a fraud model, it is more important to minimize the number of false positives than it is to catch all the frauds, making a high recall more important than a high precision.  Since the recall was lower than the precision for the random forest model, it may actually be a less desirable choice than the decision tree, especially when the need for explainability is taken into account.  Balancing the data to increase the proportion of frauds could address this issue, allowing us to generate a more accurate model without too high of a false positive rate."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d890744",
      "metadata": {
        "id": "2d890744"
      },
      "source": [
        "# Next Steps: Advanced Model Enhancement and Evaluation\n",
        "\n",
        "## Objective\n",
        "Apply more sophisticated techniques in model enhancement and evaluation within the context of fraud detection.\n",
        "\n",
        "## Tasks\n",
        "1. **Balancing the Data**:\n",
        "   - Utilize a technique like SMOTE or undersampling to balance the dataset.\n",
        "   - Rebuild the Random Forest model using the balanced dataset.\n",
        "2. **Cross-Validation**:\n",
        "   - Implement 5-fold cross-validation for the Random Forest model.\n",
        "   - Analyze the model's performance and stability based on cross-validation results.\n",
        "3. **Feature Importance Analysis**:\n",
        "   - Determine feature importance using the Random Forest model.\n",
        "   - Present the feature importances in a table and a graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "287ac32b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "287ac32b",
        "outputId": "bddd5834-2a07-4d0e-fb40-7d282e45cd69"
      },
      "outputs": [],
      "source": [
        "# Use SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE to the previously defined train test splits\n",
        "smote = SMOTE(\n",
        "    sampling_strategy='auto',  # oversample all minority classes to match the majority\n",
        "    k_neighbors=5,             # default number of nearest neighbors for synthetic sampling\n",
        "    random_state=42\n",
        ")\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Before SMOTE:\", y_train.value_counts().to_dict())\n",
        "print(\" After SMOTE:\", y_train_res.value_counts().to_dict())\n",
        "\n",
        "# Refit the Random Forest model on the balanced data\n",
        "model2.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Do the predictions, and print the classification report\n",
        "y_pred = model2.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cr6roDEEf_BQ",
      "metadata": {
        "id": "cr6roDEEf_BQ"
      },
      "source": [
        "Using the balancing procedure, we get higher precision, recall and F1 scores without as much risk of overfitting.  To check this, we perform five-fold cross validation on the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z4-3qyKsgOv6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4-3qyKsgOv6",
        "outputId": "68f5e458-64c0-400a-ac32-cb4e4d4af7c3"
      },
      "outputs": [],
      "source": [
        "#To do this, we need to create a pipeline and import the necessary cross-validation and scoring libraries\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# Build the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('model2', RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=4,             # prune trees after 4 levels\n",
        "        min_samples_split=5,     # require at least 5 samples to split a node\n",
        "        min_samples_leaf=2,      # force leaves to have ≥2 samples\n",
        "        random_state=42          # for reproducibility\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Specify the scoring metrics\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score, average='binary'),\n",
        "    'recall': make_scorer(recall_score, average='binary'),\n",
        "    'f1': make_scorer(f1_score, average='binary'),\n",
        "}\n",
        "\n",
        "# Run 5-fold CV\n",
        "cv_results = cross_validate(\n",
        "    pipeline,\n",
        "    X, y,\n",
        "    cv=5,\n",
        "    scoring=scoring,\n",
        "    return_train_score=False,  # only test scores\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Summarize the results\n",
        "for metric in scoring:\n",
        "    scores = cv_results[f'test_{metric}']\n",
        "    print(f\"{metric.capitalize():<10}: \"\n",
        "          f\"Mean = {scores.mean():.3f}, \"\n",
        "          f\"Std = {scores.std():.3f}\")\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score, average='binary'),\n",
        "    'recall': make_scorer(recall_score, average='binary'),\n",
        "    'f1': make_scorer(f1_score, average='binary'),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FFLy-98K7jAI",
      "metadata": {
        "id": "FFLy-98K7jAI"
      },
      "source": [
        "Analyzing the cross-validation results, we see the greatest variation in precision, which is also lower than recall, which is a good result for a fraud model.  This gives us confidence that the random forest is a good choice for our project, even though the example that we built before had a higher precision than recall.  The overall results likewise give us confidence in the results from the single model, because they show that the high scores are robust over the entire dataset, not just the section that we randomly set aside as a test set in the earlier run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kHKWhsFW8QDe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "kHKWhsFW8QDe",
        "outputId": "68bd771b-ddbe-4807-cbfe-41ede2a6e169"
      },
      "outputs": [],
      "source": [
        "# Extract importances\n",
        "importances = model2.feature_importances_\n",
        "feature_names = X.columns\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Put importances into a DataFrame\n",
        "df_importances = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# Sort descending and display\n",
        "df_importances = df_importances.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
        "print(df_importances)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
        "plt.xticks(range(len(importances)), feature_names[indices], rotation=90)\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C1SL1ldl960i",
      "metadata": {
        "id": "C1SL1ldl960i"
      },
      "source": [
        "From the preceding table and plot, we can see that the ratio to median purchase price is the most important feature in determining whether or not a record is classified as a fraud, and this is indeed the top node of the decision tree model.  Specifically, if the ratio is 4 or greater, the purchase is much more risky. After that, online orders are riskier than in-person orders, probably because identity verification is more difficult in an online environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QdimLKY0AUUK",
      "metadata": {
        "id": "QdimLKY0AUUK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aiml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
